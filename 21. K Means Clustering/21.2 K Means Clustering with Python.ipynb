{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# K Means Clustering with Python\n",
    "\n",
    "This notebook is just a code reference for the video lecture and reading.\n",
    "\n",
    "## Method Used\n",
    "\n",
    "K Means Clustering is an unsupervised learning algorithm that tries to cluster data based on their similarity. Unsupervised learning means that there is no outcome to be predicted, and the algorithm just tries to find patterns in the data. In k means clustering, we have the specify the number of clusters we want the data to be grouped into. The algorithm randomly assigns each observation to a cluster, and finds the centroid of each cluster. Then, the algorithm iterates through two steps:\n",
    "Reassign data points to the cluster whose centroid is closest. Calculate new centroid of each cluster. These two steps are repeated till the within cluster variation cannot be reduced any further. The within cluster variation is calculated as the sum of the euclidean distance between the data points and their respective cluster centroids."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* In this lecture we will see how to use SciKit-Learn to implement K Means Clustering Algorithm. We will also see how to create artificial data with SKLearn's capabilities."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:35:20.088653Z",
     "start_time": "2019-06-03T01:35:17.840165Z"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **NOTE** : As unsupervised means, we are not trying to predict some sort of outcome but we are trying to find patterns in the data. In K means clustering we have to specify the number of clusters we want the data to be grouped in.\n",
    "\n",
    "* Now we will see how to use SKLearn to generate some artificial data. Real data to be used in portfolio project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:35:23.261871Z",
     "start_time": "2019-06-03T01:35:22.509592Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "# make_blobs generate blob like data where we can add cluster std. deviation too, features we need, centers etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:35:23.781494Z",
     "start_time": "2019-06-03T01:35:23.775540Z"
    }
   },
   "outputs": [],
   "source": [
    "# Create artificial data that we will be using.\n",
    "data = make_blobs(n_samples=200,n_features=2,centers=4,cluster_std=1.8,random_state=101)\n",
    "#Keep random state same to have similar blobs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:35:47.863398Z",
     "start_time": "2019-06-03T01:35:47.821510Z"
    }
   },
   "source": [
    "* Data is a tuple and first element in that tuple gives us numpy array.\n",
    "* Numpy array data[0] is simply number of samples and 2 columns of features.\n",
    "* It's shape is 200,2 for precisely that reason."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:38:35.579951Z",
     "start_time": "2019-06-03T01:38:35.575999Z"
    }
   },
   "outputs": [],
   "source": [
    "# data\n",
    "# data[0]\n",
    "data[0].shape\n",
    "# And this random data will have 4 blobs in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:41:04.877388Z",
     "start_time": "2019-06-03T01:41:04.708824Z"
    }
   },
   "outputs": [],
   "source": [
    "# Plotting the blobs to get a better idea.\n",
    "\n",
    "# Grabbing all the rows and first column which we plot against all the rows and second column.\n",
    "plt.scatter(data[0][:,0],data[0][:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above we can see there are 2 blobs for sure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:42:39.067021Z",
     "start_time": "2019-06-03T01:42:39.062068Z"
    }
   },
   "outputs": [],
   "source": [
    "# Looking at second item we get a list to which cluster a blob belongs to which can be seen as below :\n",
    "data[1]\n",
    "# We can plot the above scatter plot using data[1] in a hue kind of manner to have distinguished clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:44:35.723668Z",
     "start_time": "2019-06-03T01:44:35.616953Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap=\"rainbow\")\n",
    "# This is how we can use SkLearn to create artificial data for clustering. \n",
    "# make_blobs is a really nice tool you can use to play around with some of the ML models when we do not want to deal with\n",
    "# a real dataset, we can just make our own artificial data and add cluster_std for us to distinguish blobs manually."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We can see 1 blob is really separate compared to other 3, where we see some amount of noise.\n",
    "- Now we see how to use SkLearn to create a K Means Clustering algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T01:59:25.395070Z",
     "start_time": "2019-06-03T01:59:25.391081Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- As K Means is unsupervised so it will start assigning each observation to some cluster and find centroid of each cluster.\n",
    "- Then algorithm iterates through 2 following steps :\n",
    "    - Reassign data points to the cluster whose centroid is closest\n",
    "    - Calculate the new centroid for each cluster and keeps repeating it until cluster variation can't be reduced anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:03:02.501195Z",
     "start_time": "2019-06-03T02:03:02.498206Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4) \n",
    "# NOTE: We have to know number of expected clusters beforehand in KMeans Clustering Algo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:03:33.421196Z",
     "start_time": "2019-06-03T02:03:33.394211Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.fit(data[0]) # Fit to the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:03:55.563838Z",
     "start_time": "2019-06-03T02:03:55.558851Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.cluster_centers_ # Returns array of actual centers of the clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:07:31.327762Z",
     "start_time": "2019-06-03T02:07:31.323771Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans.labels_ \n",
    "# Returns the labels our algorithm believes to be true for the given clusters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- NOTE : If we are working with real data and we did not have real labels then this is the final stage. We wouldn't be able to compare anything to real values. Since here we do know the correct labels present inside data[1] we compare these with kmeans.labels_ we got above for accuracy of prediction.\n",
    "\n",
    "- In general we wouldn't use kmeans cluster to predict labels rather use it to find labels since here we have real labels for data we created as well as predicted label in kmeans.labels_ so we give it a try for knowing the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:28:14.646235Z",
     "start_time": "2019-06-03T02:28:14.435797Z"
    }
   },
   "outputs": [],
   "source": [
    "fig , (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(10,6))\n",
    "\n",
    "ax1.set_title('K Means Predicted')\n",
    "ax1.scatter(data[0][:,0],data[0][:,1],c=kmeans.labels_,cmap='rainbow') # Color as per label\n",
    "\n",
    "ax2.set_title('Original Data')\n",
    "ax2.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='rainbow') # Color as per data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are creating a subplot of 1 row, 2 columns and the plots having the same axes and using tuple unpacking to grab these\n",
    "- 2 sets of axes, these first set of axes ax1 will be plotting original data and colour the data based on what algorithm thought labels should look like.\n",
    "- Another plot ax2 will plot the original data and color it as per the factually correct blobs.\n",
    "- Also remember that even if 2 plots have different clusters, that is not our goal here, as we can see that even with different colours approximately the clusters represented are almost same in shape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clusters with different k values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:57:34.681310Z",
     "start_time": "2019-06-03T02:57:34.482807Z"
    }
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(data[0])\n",
    "fig , (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(10,6))\n",
    "\n",
    "ax1.set_title('K Means Predicted')\n",
    "ax1.scatter(data[0][:,0],data[0][:,1],c=kmeans.labels_,cmap='rainbow') # Color as per label\n",
    "\n",
    "ax2.set_title('Original Data')\n",
    "ax2.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='rainbow') # Color as per data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T02:57:44.851761Z",
     "start_time": "2019-06-03T02:57:44.636299Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=3)\n",
    "kmeans.fit(data[0])\n",
    "fig , (ax1,ax2) = plt.subplots(1,2,sharey=True,figsize=(10,6))\n",
    "\n",
    "ax1.set_title('K Means Predicted')\n",
    "ax1.scatter(data[0][:,0],data[0][:,1],c=kmeans.labels_,cmap='rainbow') # Color as per label\n",
    "\n",
    "ax2.set_title('Original Data')\n",
    "ax2.scatter(data[0][:,0],data[0][:,1],c=data[1],cmap='rainbow') # Color as per data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE** : The colors are meaningless in reference between the two plots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
