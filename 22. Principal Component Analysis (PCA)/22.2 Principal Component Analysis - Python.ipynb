{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Principal Component Analysis\n",
    "\n",
    "Let's discuss PCA! Since this isn't exactly a full machine learning algorithm, but instead an unsupervised learning algorithm, we will just have a lecture on this topic, but no full machine learning project (although we will walk through the cancer set with PCA).\n",
    "\n",
    "## PCA Review\n",
    "\n",
    "Make sure to watch the video lecture and theory presentation for a full overview of PCA! \n",
    "Remember that PCA is just a transformation of your data and attempts to find out what features explain the most variance in your data. For example:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- This is just an extension of Python and SkLearn to illustrate concept of PCA.\n",
    "- We won't be having a portfolio project, although we will be using a Cancer dataset.\n",
    "- PCA is just transformation of data to find out which features explain most of the variance in the data.\n",
    "<img src='PCA.png' />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explanation of Image Above :\n",
    "- If we have 2 components as in image on top left, we try to get rid of components which do not explain a lot of variance in the data.\n",
    "- We can transform the data with either first or second component dropped and then see for variance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:05:44.479622Z",
     "start_time": "2019-06-03T21:05:43.751396Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Data\n",
    "\n",
    "Let's work with the cancer data set again since it had so many features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:08:38.616748Z",
     "start_time": "2019-06-03T21:08:38.613790Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "# Getting dataset directly from SkLearn, Sklearn has these built-in datasets as references to use case of SkLearn in documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:06:01.925084Z",
     "start_time": "2019-06-03T21:06:01.907133Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer = load_breast_cancer()\n",
    "# Setting a variable, and loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:17:35.374317Z",
     "start_time": "2019-06-03T21:17:35.369327Z"
    }
   },
   "outputs": [],
   "source": [
    "type(cancer) # This dataset acts like dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:06:06.943005Z",
     "start_time": "2019-06-03T21:06:06.938019Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:06:13.166544Z",
     "start_time": "2019-06-03T21:06:13.162587Z"
    }
   },
   "outputs": [],
   "source": [
    "print(cancer['DESCR']) # For description, notice how Attributes number is really high for less number of instances.\n",
    "# There are target and their names here and we would have done prediction whether tumour is benign or malignant but\n",
    "# that would have been case for supervised learning, here we find which components are most important explaining\n",
    "# the most of the variance of the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:06:24.218171Z",
     "start_time": "2019-06-03T21:06:24.215175Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame(cancer['data'],columns=cancer['feature_names'])\n",
    "#(['DESCR', 'data', 'feature_names', 'target_names', 'target'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:06:34.033606Z",
     "start_time": "2019-06-03T21:06:34.015656Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:21:44.036985Z",
     "start_time": "2019-06-03T21:21:44.032994Z"
    }
   },
   "outputs": [],
   "source": [
    "cancer['target_names']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We won't be applying any ML algorithm for prediction/classification, instead we will do PCA, the reason behind that is if we were given this dataset and we were planning to apply a classification algorithm on it then we would have done PCA first, to get an idea of what is important to see if tumour belongs to class 0 or 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA Visualization\n",
    "\n",
    "As we've noticed before it is difficult to visualize high dimensional data, we can use PCA to find the first two principal components, and visualize the data in this new, two-dimensional space, with a single scatter-plot. Before we do this though, we'll need to scale our data so that each feature has a single unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:24:32.267683Z",
     "start_time": "2019-06-03T21:24:32.263732Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We scale our data so that each feature has a single unit variance, before we actually use PCA on the cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:25:55.387107Z",
     "start_time": "2019-06-03T21:25:55.384115Z"
    }
   },
   "outputs": [],
   "source": [
    "# We have done this before, we call it like we would do for any other estimator in SkLearn.\n",
    "scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:26:35.161509Z",
     "start_time": "2019-06-03T21:26:35.155525Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler.fit(df) # Fitting the scaler to features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:27:01.676444Z",
     "start_time": "2019-06-03T21:27:01.669463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Now we transform\n",
    "scaled_data = scaler.transform(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PCA with Scikit Learn uses a very similar process to other preprocessing functions that come with SciKit Learn. We instantiate a PCA object, find the principal components using the fit method, then apply the rotation and dimensionality reduction by calling transform().\n",
    "\n",
    "We can also specify how many components we want to keep when creating the PCA object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:27:51.324151Z",
     "start_time": "2019-06-03T21:27:51.321159Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:28:53.231447Z",
     "start_time": "2019-06-03T21:28:53.229438Z"
    }
   },
   "outputs": [],
   "source": [
    "pca = PCA(n_components=2) # We try to visualise the entire 3 dimensional dataset just by using two principal components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:29:06.128774Z",
     "start_time": "2019-06-03T21:29:06.077911Z"
    }
   },
   "outputs": [],
   "source": [
    "pca.fit(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:29:42.474591Z",
     "start_time": "2019-06-03T21:29:42.470633Z"
    }
   },
   "outputs": [],
   "source": [
    "# Transform the data to its first principal components.\n",
    "x_pca = pca.transform(scaled_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:51:16.001750Z",
     "start_time": "2019-06-03T21:51:15.996802Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:51:21.874523Z",
     "start_time": "2019-06-03T21:51:21.869539Z"
    }
   },
   "outputs": [],
   "source": [
    "x_pca.shape # Transformed and reduced to first two principal component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T21:57:17.209738Z",
     "start_time": "2019-06-03T21:57:17.052153Z"
    }
   },
   "outputs": [],
   "source": [
    "# After reduction of 3 dimensions to 2, we will plot these dimensions using matplotlib\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.scatter(x_pca[:,0],x_pca[:,1],c=cancer['target'],cmap='plasma')\n",
    "# c = cancer['target'] colours the points according to benign or malignant.\n",
    "# Grab all the rows from column 0 and plot these against all the rows from column 1\n",
    "plt.xlabel(\"First Principal Component\")\n",
    "plt.ylabel(\"Second Principal Component\")\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The plot above shows the power of PCA, as based off of only first and second component we can see we have a separation which is very clearly depicting what does benign and malignant tumours look like.\n",
    "\n",
    "- Clearly by using these two components we can easily separate these two classes.\n",
    "\n",
    "## Interpreting the components \n",
    "\n",
    "Unfortunately, with this great power of dimensionality reduction, comes the cost of being able to easily understand what these components represent.\n",
    "\n",
    "The components correspond to combinations of the original features, the components themselves are stored as an attribute of the fitted PCA object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T22:02:31.695872Z",
     "start_time": "2019-06-03T22:02:31.688890Z"
    }
   },
   "outputs": [],
   "source": [
    "pca.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this numpy matrix array, each row represents a principal component, and each column relates back to the original features. we can visualize this relationship with a heatmap:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T22:04:23.770521Z",
     "start_time": "2019-06-03T22:04:23.767530Z"
    }
   },
   "outputs": [],
   "source": [
    "df_comp = pd.DataFrame(pca.components_,columns=cancer['feature_names'])\n",
    "# Has relationship for each of the 30 features for Prinicpal Component 0 and 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T22:04:45.164679Z",
     "start_time": "2019-06-03T22:04:44.907368Z"
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "sns.heatmap(df_comp,cmap='plasma')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-06-03T22:03:14.950232Z",
     "start_time": "2019-06-03T22:03:14.946280Z"
    }
   },
   "source": [
    "This heatmap and the color bar basically represent the correlation between the various feature and the principal component itself.\n",
    "Each principal component is shown here as a row, higher the number or hotter a colour looks like i.e. towards yellow, it is more correlated to a specific feature in column.\n",
    "\n",
    "\n",
    "- **Do some extra reading on PCA from ISLR.**\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Hopefully this information is useful to you when dealing with high dimensional data!\n",
    "After having principal components we can go ahead and feed in the reduced version x_pca into a classification algo. Say a logistic regression on x_pca instead of doing that on entire dataframe of features. As we see in plot the 2 categories are almost separable by a straight line, we should use SVM with data of this nature preferrably."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
