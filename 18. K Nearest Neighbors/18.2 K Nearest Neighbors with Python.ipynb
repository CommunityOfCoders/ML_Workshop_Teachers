{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K Nearest Neighbors with Python\n",
    "\n",
    "You've been given a classified data set from a company! They've hidden the feature column names but have given you the data and the target classes. \n",
    "\n",
    "We'll try to use KNN to create a model that directly predicts a class for a new data point based off of the features.\n",
    "\n",
    "Let's grab it and use it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.352588Z",
     "start_time": "2019-05-26T09:14:00.349557Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the Data\n",
    "\n",
    "Set index_col=0 to use the first column as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.366509Z",
     "start_time": "2019-05-26T09:14:00.353547Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Classified Data\",index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.378479Z",
     "start_time": "2019-05-26T09:14:00.367507Z"
    }
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize the Variables\n",
    "\n",
    "Because the KNN classifier predicts the class of a given test observation by identifying the observations that are nearest to it, the scale of the variables matters. Any variables that are on a large scale will have a much larger effect on the distance between the observations, and hence on the KNN classifier, than variables that are on a small scale. That is why while using KNN we standardize everything on a standard scale."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.383492Z",
     "start_time": "2019-05-26T09:14:00.380473Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler # It will look a lot like as if it was a ML model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.389450Z",
     "start_time": "2019-05-26T09:14:00.384462Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler = StandardScaler() # Create an instance of StandardScale as we would for some ML algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:00.397430Z",
     "start_time": "2019-05-26T09:14:00.390447Z"
    }
   },
   "outputs": [],
   "source": [
    "scaler.fit(df.drop('TARGET CLASS',axis=1))\n",
    "# As we want to fit this to our training data and not the actual TARGET CLASS that's why drop for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:04.010382Z",
     "start_time": "2019-05-26T09:14:04.006428Z"
    }
   },
   "outputs": [],
   "source": [
    "scaled_features = scaler.transform(df.drop('TARGET CLASS',axis=1))\n",
    "# Transform method performs the standardization by centering and scaling.\n",
    "# Gives us a scaled version of values in df excluding TARGET CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:14:04.795038Z",
     "start_time": "2019-05-26T09:14:04.784067Z"
    }
   },
   "outputs": [],
   "source": [
    "df_feat = pd.DataFrame(scaled_features,columns=df.columns[:-1]) # Creating a feature DataFrame\n",
    "# Passing in our scaled_features array as data and for column names we specify df.columns but the last TARGET CLASS so [:-1]\n",
    "df_feat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:16:06.995049Z",
     "start_time": "2019-05-26T09:16:06.991059Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:16:11.003304Z",
     "start_time": "2019-05-26T09:16:10.998353Z"
    }
   },
   "outputs": [],
   "source": [
    "X = scaled_features\n",
    "Y = df['TARGET CLASS']\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_features,df['TARGET CLASS'],test_size=0.30,random_state = 101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using KNN\n",
    "\n",
    "Remember that we are trying to come up with a model to predict whether someone will TARGET CLASS or not. We'll start with k=1.\n",
    "And then we will move on towards using Elbow Method to choose the ideal K value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:16:51.952167Z",
     "start_time": "2019-05-26T09:16:51.949174Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:41:43.479075Z",
     "start_time": "2019-05-26T09:41:43.475085Z"
    }
   },
   "outputs": [],
   "source": [
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "# By specifying n_neighbors it means number of neighbors we want for this model. we set it as 1 for this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:42:09.123840Z",
     "start_time": "2019-05-26T09:42:09.118845Z"
    }
   },
   "outputs": [],
   "source": [
    "knn.fit(X_train,y_train) # Fitting on our training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:44:37.887195Z",
     "start_time": "2019-05-26T09:44:37.873232Z"
    }
   },
   "outputs": [],
   "source": [
    "pred = knn.predict(X_test)\n",
    "pred# Shows to which class a particular prediction belongs to."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions and Evaluation\n",
    "\n",
    "Let's Evaluate KNN model! After this we do elbow method to find out an optimal k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:43:06.770021Z",
     "start_time": "2019-05-26T09:43:06.767064Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:43:40.726428Z",
     "start_time": "2019-05-26T09:43:40.721467Z"
    }
   },
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:43:42.277510Z",
     "start_time": "2019-05-26T09:43:42.272527Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So far model looks good with an accuracy of TP+TN/Total = (151+126)/300 = 0.92.\n",
    "- Let's see if we can even further improve the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a K Value\n",
    "\n",
    "Let's go ahead and use the elbow method to pick a good K Value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:53:17.271869Z",
     "start_time": "2019-05-26T09:53:16.831011Z"
    }
   },
   "outputs": [],
   "source": [
    "error_rate = [] # First we set error_rate as an empty list. Then we iterate on many models using different k value.\n",
    "# And we plot out the error rate and see which one has the lowest error rate.\n",
    "\n",
    "# Will take some time\n",
    "for i in range(1,40): # Check every k value from 1 to 40 for all of those values we will call KNeighborsClassifier, with\n",
    "    # n_neighbors = i, then we fit that model, then we say pred_i off of test set and then to error_rate we append\n",
    "    # mean of pred_i != y_test. AKA Average error rate being added to error_rate list for every iteration from 1 to 40.\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train,y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    error_rate.append(np.mean(pred_i != y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:59:45.634110Z",
     "start_time": "2019-05-26T09:59:45.503460Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10,5)) # A little larger than usual for better understanding purpose.\n",
    "plt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n",
    "         markerfacecolor='red', markersize=10) # Plot of range(1,40) vs error_rate\n",
    "plt.title('Error Rate vs. K Value')\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('Error Rate')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We notice that we start with error of around 0.075 and it went up for k = 2 and then it went drastically down for k=3 and so on.\n",
    "\n",
    "Here we can see that that after arouns K>23 the error rate just tends to hover around 0.06-0.05 Let's retrain the model with that and check the classification report!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:02:10.958660Z",
     "start_time": "2019-05-26T09:02:10.941671Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\n",
    "knn = KNeighborsClassifier(n_neighbors=1)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=1')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T10:00:47.059519Z",
     "start_time": "2019-05-26T10:00:47.040571Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOW WITH K=17\n",
    "knn = KNeighborsClassifier(n_neighbors=17)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=23')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-05-26T09:02:22.064903Z",
     "start_time": "2019-05-26T09:02:22.045982Z"
    }
   },
   "outputs": [],
   "source": [
    "# NOW WITH K=23\n",
    "knn = KNeighborsClassifier(n_neighbors=23)\n",
    "\n",
    "knn.fit(X_train,y_train)\n",
    "pred = knn.predict(X_test)\n",
    "\n",
    "print('WITH K=23')\n",
    "print('\\n')\n",
    "print(confusion_matrix(y_test,pred))\n",
    "print('\\n')\n",
    "print(classification_report(y_test,pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Great job!\n",
    "\n",
    "We were able to squeeze some more performance out of our model by tuning to a better K value!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
